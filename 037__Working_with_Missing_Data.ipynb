{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "037__Working_with_Missing_Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9DMBTfiY67Mhe+PsKtxyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rossel/DataQuest_Courses/blob/master/037__Working_with_Missing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PWQ-EVGT2s_"
      },
      "source": [
        "# COURSE 5/6: DATA CLEANING IN PYTHON: ADVANCED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THaX315BT2wD"
      },
      "source": [
        "# MISSION 4: Working with Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCtUhKGVV2Fl"
      },
      "source": [
        "Identify and deal with missing and incorrect data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfk12M-4TwZU"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1XTUbRXeCo5"
      },
      "source": [
        "In the last mission of this course, we're going to learn more about working with missing data. As we learned in [Working with Missing and Duplicate Data](https://app.dataquest.io/m/347/working-with-missing-and-duplicate-data), data can be missing for a variety of reasons.\n",
        "\n",
        "In this mission, we'll learn how to handle missing data without having to drop rows and columns using data on motor vehicle collisions released by [New York City](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95) and published on the NYC OpenData website. There is data on over 1.5 million collisions dating back to 2012, with additional data continuously added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPuLjPelec0n"
      },
      "source": [
        "We'll work with an extract of the full data: Crashes from the year 2018. We made several modifications to the data for teaching purposes, including randomly sampling the data to reduce its size. You can download the data set from this mission by using the data set preview tool at the top of the \"script.py\" codebox on the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEYXuQD3ej73"
      },
      "source": [
        "Our data set is in a CSV called `nypd_mvc_2018.csv`. We can read our data into a pandas dataframe and inspect the first few rows of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zbhVrbR2n44"
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQVsg_sh2o4j"
      },
      "source": [
        "# Once you have completed verification, go to the CSV file in Google Drive, right-click on it and select “Get shareable link”, and cut out the unique id in the link.\n",
        "# https://drive.google.com/file/d/137_5T2t59aksuPV2aLP5VldshtCb9vN1/view?usp=sharing\n",
        "id = \"137_5T2t59aksuPV2aLP5VldshtCb9vN1\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgFvCD-32wdh"
      },
      "source": [
        "# Download the dataset\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('nypd_mvc_2018.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzR-06l4hQ_q"
      },
      "source": [
        "# Once you have completed verification, go to the CSV file in Google Drive, right-click on it and select “Get shareable link”, and cut out the unique id in the link.\n",
        "# https://drive.google.com/file/d/111gD0MnU_ekqTMK-KYgNt7uP5WEVZJCl/view?usp=sharing\n",
        "id = \"111gD0MnU_ekqTMK-KYgNt7uP5WEVZJCl\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tronbm5whSbv"
      },
      "source": [
        "# Download the dataset\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('supplemental_data.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1hsGcc_gVSW",
        "outputId": "f808a897-e6a7-411f-f691-1eb5ce9e4e58"
      },
      "source": [
        "import pandas as pd\n",
        "mvc = pd.read_csv(\"nypd_mvc_2018.csv\")\n",
        "\n",
        "# unknown what np should be...\n",
        "# np = pd.read_csv(\"supplemental_data.csv\")\n",
        "\n",
        "print(mvc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       unique_key        date  ... cause_vehicle_4 cause_vehicle_5\n",
            "0         3869058  2018-03-23  ...             NaN             NaN\n",
            "1         3847947  2018-02-13  ...             NaN             NaN\n",
            "2         3914294  2018-06-04  ...             NaN             NaN\n",
            "3         3915069  2018-06-05  ...             NaN             NaN\n",
            "4         3923123  2018-06-16  ...             NaN             NaN\n",
            "...           ...         ...  ...             ...             ...\n",
            "57859     3835191  2018-01-26  ...             NaN             NaN\n",
            "57860     3890674  2018-04-29  ...             NaN             NaN\n",
            "57861     3946458  2018-07-21  ...             NaN             NaN\n",
            "57862     3914574  2018-06-04  ...             NaN             NaN\n",
            "57863     4034882  2018-11-29  ...             NaN             NaN\n",
            "\n",
            "[57864 rows x 26 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQf19WbclIIW"
      },
      "source": [
        "A summary of the columns and their data is below:\n",
        "\n",
        "- `unique_key`: A unique identifier for each collision.\n",
        "- `date`, `time`: Date and time of the collision.\n",
        "- `borough`: The [borough](https://en.wikipedia.org/wiki/Boroughs_of_New_York_City), or area of New York City, where the collision occurred.\n",
        "- `location`: Latitude and longitude coordinates for the collision.\n",
        "- `on_street`, `cross_street`, `off_street`: Details of the street or intersection where the collision occurred.\n",
        "- `pedestrians_injured`: Number of pedestrians who were injured.\n",
        "- `cyclist_injured`: Number of people traveling on a bicycle who were injured.\n",
        "- `motorist_injured`: Number of people traveling in a vehicle who were injured.\n",
        "- `total_injured`: Total number of people injured.\n",
        "- `pedestrians_killed`: Number of pedestrians who were killed.\n",
        "- `cyclist_killed`: Number of people traveling on a bicycle who were killed.\n",
        "- `motorist_killed`: Number of people traveling in a vehicle who were killed.\n",
        "- `total_killed`: Total number of people killed.\n",
        "- `vehicle_1` through `vehicle_5`: Type of each vehicle involved in the accident.\n",
        "- `cause_vehicle_1` through `cause_vehicle_5`: Contributing factor for each vehicle in the accident."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm4MS7lplwzU"
      },
      "source": [
        "Let's quickly recap how to count missing values. We'll start by creating a dataframe with random null values:\n",
        "```\n",
        "data = np.random.choice([1.0, np.nan],\n",
        "                        size=(3, 3),\n",
        "                        p=[.3, .7])\n",
        "df = pd.DataFrame(data, columns=['A','B','C'])\n",
        "print(df)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV2BdIIpglcG"
      },
      "source": [
        "```\n",
        "_    A    B    C\n",
        "0  NaN  NaN  1.0\n",
        "1  NaN  1.0  1.0\n",
        "2  1.0  NaN  NaN\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDic64LCoZdZ"
      },
      "source": [
        "Next, we can use the `DataFrame.isnull()` [method](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) to identify which values are null:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5COHAesmgqck"
      },
      "source": [
        "```\n",
        "print(df.isnull())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ6U4A6bgr6m"
      },
      "source": [
        "```\n",
        "_      A      B      C\n",
        "0   True   True  False\n",
        "1   True  False  False\n",
        "2  False   True   True\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szKgvo21okSh"
      },
      "source": [
        "We can chain the result to `DataFrame.sum()` [method](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) to count the number of null values in each column:\n",
        "\n",
        "```\n",
        "print(df.isnull().sum())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOIDTM1ug0b8"
      },
      "source": [
        "```\n",
        "A    2\n",
        "B    2\n",
        "C    1\n",
        "dtype: int64\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltv_RxLNosSA"
      },
      "source": [
        "Let's use this technique to count the null values in our data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q62ex436pNOA"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We have read the CSV file into a pandas dataframe called `mvc`.\n",
        "\n",
        "1. Create a series that counts the number of null values in each of the columns in the `mvc` dataframe. Assign the result to `null_counts`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUOKYuKvzbhl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "6382eb9e-54ae-430d-ebd3-ea95d72ea193"
      },
      "source": [
        "#### Below the solution to make the next chapter work\n",
        "data = np.random.choice([1.0, np.nan],\n",
        " size=(3, 3), p=[.3, .7])\n",
        "df = pd.DataFrame(data, columns=['A','B','C'])\n",
        "print(df)\n",
        "\n",
        "null_counts = mvc.isnull().sum()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d7cc5aca1d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### Below the solution to make the next chapter work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m data = np.random.choice([1.0, np.nan],\n\u001b[0m\u001b[1;32m      3\u001b[0m  size=(3, 3), p=[.3, .7])\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'random'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNqQeGQN3Wmq"
      },
      "source": [
        "## 2. Verifying the Total Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yey--i93Y8_"
      },
      "source": [
        "To give us a better picture of the null values in the data, let's calculate the percentage of null values in each column. Below, we divide the number of null values in each column by the total number of values in the data set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Be6DElQ3vvS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "6e2469b2-568f-48c8-b534-e5646b6ca0e8"
      },
      "source": [
        "null_counts_pct = null_counts / mvc.shape[0] * 100"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e2a9ac809af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnull_counts_pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnull_counts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'null_counts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9odWbbgs3yDP"
      },
      "source": [
        "We'll then add both the counts and percentages to a dataframe to make them easier to compare:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryxNnNMA3ziM"
      },
      "source": [
        "null_df = pd.DataFrame({'null_counts': null_counts, 'null_pct': null_counts_pct})\n",
        "# Rotate the dataframe so that rows become columns and vice-versa\n",
        "null_df = null_df.T.astype(int)\n",
        "\n",
        "print(null_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcMHjL8o318F"
      },
      "source": [
        "About a third of the columns have no null values, with the rest ranging from less than 1% to 99%!\n",
        "\n",
        "To make things easier, let's start by looking at the group of columns that relate to people killed in collisions.\n",
        "\n",
        "We'll use list comprehension to reduce our summary dataframe to just those columns:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsG_L7kjfGEr"
      },
      "source": [
        "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
        "print(null_df[killed_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYTGQjkSfLCO"
      },
      "source": [
        "We can see that each of the individual categories have no missing values, but the `total_killed` column has five missing values.\n",
        "\n",
        "One option for handling this would be to remove – or drop – those five rows. This would be a reasonably valid choice since it's a tiny portion of the data, but let's think about what other options we have first.\n",
        "\n",
        "If you think about it, the total number of people killed should be the sum of each of the individual categories. We might be able to \"fill in\" the missing values with the sums of the individual columns for that row. The technical name for filling in a missing value with a replacement value is called **imputation**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd-8ID9dfRPt"
      },
      "source": [
        "Let's look at how we could explore the values where the `total_killed` isn't equal to the sum of the other three columns. We'll illustrate this process using a series of diagrams. The diagrams won't contain values, they'll just show a grid to represent the values.\n",
        "\n",
        "Let's start with a dataframe of just the four columns relating to people killed:\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_1.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkQ323CEfjcH"
      },
      "source": [
        "We then select just the first three columns, and manually sum each row:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_2.svg)\n",
        "\n",
        "We then compare the manual sum to the original total column to create a boolean mask where equivalent values are *not* equal:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_3.svg)\n",
        "\n",
        "Lastly, we use the boolean mask to filter the original dataframe to include only rows where the manual sum and original aren't equal:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_4.svg)\n",
        "\n",
        "Let's use this strategy to look at the rows that don't match up!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO_slk6_fz3K"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We created a dataframe `killed`, containing the five columns that relate to people killed in collisions.\n",
        "\n",
        "1. Select the first three columns from `killed` and sum each row. Assign the result to `killed_manual_sum`.\n",
        "2. Create a boolean mask that checks whether each value in `killed_manual_sum` is not equal to the values in the `total_killed` column. Assign the boolean mask to `killed_mask`.\n",
        "3. Use `killed_mask` to filter the rows in `killed`. Assign the result to `killed_non_eq`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia7UF6e4f1BP"
      },
      "source": [
        "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
        "killed = mvc[killed_cols].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10x3XqHHf2AV"
      },
      "source": [
        "### Part of the solution to make the next chapter work\n",
        "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
        "killed = mvc[killed_cols].copy()\n",
        "killed_manual_sum = killed.iloc[:,:3].sum(axis=1)\n",
        "killed_mask = killed_manual_sum != killed['total_killed']\n",
        "killed_non_eq = killed[killed_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS_B2Wq43ZTD"
      },
      "source": [
        "## 3. Filling and Verifying the Killed and Injured Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ha8jIZl3ZVq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VghEIrKK3ZX3"
      },
      "source": [
        "## 4. Assigning the Corrected Data Back to the Main Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8j4pinE3ZhG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS8po7Uc3ZmS"
      },
      "source": [
        "## 5. Visualizing Missing Data with Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDP4EJ1Q3Zpz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_jLG9343Zsz"
      },
      "source": [
        "## 6. Analyzing Correlations in Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA88kToh3Zv8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58lresB53Zz1"
      },
      "source": [
        "## 7. Finding the Most Common Values Across Multiple Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qtRs7jM3Z3I"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMAeYu3c3Z7M"
      },
      "source": [
        "## 8. Filling Unknown Values with a Placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTIoZKUG3Z_F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ66Zvek3aDE"
      },
      "source": [
        "## 9. Missing Data in the \"Location\" Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zQcQWgX3aJc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x68M_JvG3l_Q"
      },
      "source": [
        "## 10. Imputing Location Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY0zriW-3n2u"
      },
      "source": [
        ""
      ]
    }
  ]
}