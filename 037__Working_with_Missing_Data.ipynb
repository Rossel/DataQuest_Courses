{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "037__Working_with_Missing_Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdQHZUfSBR9pQEDp2rNuQE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rossel/DataQuest_Courses/blob/master/037__Working_with_Missing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PWQ-EVGT2s_"
      },
      "source": [
        "# COURSE 5/6: DATA CLEANING IN PYTHON: ADVANCED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THaX315BT2wD"
      },
      "source": [
        "# MISSION 4: Working with Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCtUhKGVV2Fl"
      },
      "source": [
        "Identify and deal with missing and incorrect data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfk12M-4TwZU"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1XTUbRXeCo5"
      },
      "source": [
        "In the last mission of this course, we're going to learn more about working with missing data. As we learned in [Working with Missing and Duplicate Data](https://app.dataquest.io/m/347/working-with-missing-and-duplicate-data), data can be missing for a variety of reasons.\n",
        "\n",
        "In this mission, we'll learn how to handle missing data without having to drop rows and columns using data on motor vehicle collisions released by [New York City](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95) and published on the NYC OpenData website. There is data on over 1.5 million collisions dating back to 2012, with additional data continuously added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPuLjPelec0n"
      },
      "source": [
        "We'll work with an extract of the full data: Crashes from the year 2018. We made several modifications to the data for teaching purposes, including randomly sampling the data to reduce its size. You can download the data set from this mission by using the data set preview tool at the top of the \"script.py\" codebox on the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEYXuQD3ej73"
      },
      "source": [
        "Our data set is in a CSV called `nypd_mvc_2018.csv`. We can read our data into a pandas dataframe and inspect the first few rows of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zbhVrbR2n44"
      },
      "source": [
        "\n",
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQVsg_sh2o4j"
      },
      "source": [
        "# Once you have completed verification, go to the CSV file in Google Drive, right-click on it and select “Get shareable link”, and cut out the unique id in the link.\n",
        "# https://drive.google.com/file/d/137_5T2t59aksuPV2aLP5VldshtCb9vN1/view?usp=sharing\n",
        "id = \"137_5T2t59aksuPV2aLP5VldshtCb9vN1\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgFvCD-32wdh"
      },
      "source": [
        "# Download the dataset\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('nypd_mvc_2018.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzR-06l4hQ_q"
      },
      "source": [
        "# Once you have completed verification, go to the CSV file in Google Drive, right-click on it and select “Get shareable link”, and cut out the unique id in the link.\n",
        "# https://drive.google.com/file/d/111gD0MnU_ekqTMK-KYgNt7uP5WEVZJCl/view?usp=sharing\n",
        "id = \"111gD0MnU_ekqTMK-KYgNt7uP5WEVZJCl\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tronbm5whSbv"
      },
      "source": [
        "# Download the dataset\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('supplemental_data.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1hsGcc_gVSW",
        "outputId": "0bc5868e-3aeb-487b-cf0e-e37baf6e0d82"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "mvc = pd.read_csv(\"nypd_mvc_2018.csv\")\n",
        "\n",
        "print(mvc)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       unique_key        date  ... cause_vehicle_4 cause_vehicle_5\n",
            "0         3869058  2018-03-23  ...             NaN             NaN\n",
            "1         3847947  2018-02-13  ...             NaN             NaN\n",
            "2         3914294  2018-06-04  ...             NaN             NaN\n",
            "3         3915069  2018-06-05  ...             NaN             NaN\n",
            "4         3923123  2018-06-16  ...             NaN             NaN\n",
            "...           ...         ...  ...             ...             ...\n",
            "57859     3835191  2018-01-26  ...             NaN             NaN\n",
            "57860     3890674  2018-04-29  ...             NaN             NaN\n",
            "57861     3946458  2018-07-21  ...             NaN             NaN\n",
            "57862     3914574  2018-06-04  ...             NaN             NaN\n",
            "57863     4034882  2018-11-29  ...             NaN             NaN\n",
            "\n",
            "[57864 rows x 26 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQf19WbclIIW"
      },
      "source": [
        "A summary of the columns and their data is below:\n",
        "\n",
        "- `unique_key`: A unique identifier for each collision.\n",
        "- `date`, `time`: Date and time of the collision.\n",
        "- `borough`: The [borough](https://en.wikipedia.org/wiki/Boroughs_of_New_York_City), or area of New York City, where the collision occurred.\n",
        "- `location`: Latitude and longitude coordinates for the collision.\n",
        "- `on_street`, `cross_street`, `off_street`: Details of the street or intersection where the collision occurred.\n",
        "- `pedestrians_injured`: Number of pedestrians who were injured.\n",
        "- `cyclist_injured`: Number of people traveling on a bicycle who were injured.\n",
        "- `motorist_injured`: Number of people traveling in a vehicle who were injured.\n",
        "- `total_injured`: Total number of people injured.\n",
        "- `pedestrians_killed`: Number of pedestrians who were killed.\n",
        "- `cyclist_killed`: Number of people traveling on a bicycle who were killed.\n",
        "- `motorist_killed`: Number of people traveling in a vehicle who were killed.\n",
        "- `total_killed`: Total number of people killed.\n",
        "- `vehicle_1` through `vehicle_5`: Type of each vehicle involved in the accident.\n",
        "- `cause_vehicle_1` through `cause_vehicle_5`: Contributing factor for each vehicle in the accident."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm4MS7lplwzU"
      },
      "source": [
        "Let's quickly recap how to count missing values. We'll start by creating a dataframe with random null values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJDnfASNiCC9",
        "outputId": "8182da36-011e-4b44-8826-fb4263a935c1"
      },
      "source": [
        "data = np.random.choice([1.0, np.nan],\n",
        "                        size=(3, 3),\n",
        "                        p=[.3, .7])\n",
        "df = pd.DataFrame(data, columns=['A','B','C'])\n",
        "print(df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     A    B    C\n",
            "0  1.0  1.0  1.0\n",
            "1  NaN  NaN  NaN\n",
            "2  1.0  NaN  NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDic64LCoZdZ"
      },
      "source": [
        "Next, we can use the `DataFrame.isnull()` [method](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) to identify which values are null:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQgYS1jxiHiB",
        "outputId": "168dd170-f3a7-4c55-da28-c59f77b79266"
      },
      "source": [
        "print(df.isnull())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A      B      C\n",
            "0  False  False  False\n",
            "1   True   True   True\n",
            "2  False   True   True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szKgvo21okSh"
      },
      "source": [
        "We can chain the result to `DataFrame.sum()` [method](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) to count the number of null values in each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfWxQv74iKfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9fb40b3-f386-4503-b68f-52f912f8db90"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A    1\n",
            "B    2\n",
            "C    2\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltv_RxLNosSA"
      },
      "source": [
        "Let's use this technique to count the null values in our data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q62ex436pNOA"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We have read the CSV file into a pandas dataframe called `mvc`.\n",
        "\n",
        "1. Create a series that counts the number of null values in each of the columns in the `mvc` dataframe. Assign the result to `null_counts`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUOKYuKvzbhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f9f733-fa93-432b-86ff-a49f9ca461c5"
      },
      "source": [
        "#### Below the solution to make the next chapter work\n",
        "data = np.random.choice([1.0, np.nan],\n",
        " size=(3, 3), p=[.3, .7])\n",
        "df = pd.DataFrame(data, columns=['A','B','C'])\n",
        "print(df)\n",
        "\n",
        "null_counts = mvc.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     A    B    C\n",
            "0  1.0  NaN  NaN\n",
            "1  NaN  1.0  1.0\n",
            "2  NaN  NaN  NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNqQeGQN3Wmq"
      },
      "source": [
        "## 2. Verifying the Total Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yey--i93Y8_"
      },
      "source": [
        "To give us a better picture of the null values in the data, let's calculate the percentage of null values in each column. Below, we divide the number of null values in each column by the total number of values in the data set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Be6DElQ3vvS"
      },
      "source": [
        "null_counts_pct = null_counts / mvc.shape[0] * 100"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9odWbbgs3yDP"
      },
      "source": [
        "We'll then add both the counts and percentages to a dataframe to make them easier to compare:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryxNnNMA3ziM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7dc30f-414c-4c38-b923-fac5fa3925fd"
      },
      "source": [
        "null_df = pd.DataFrame({'null_counts': null_counts, 'null_pct': null_counts_pct})\n",
        "# Rotate the dataframe so that rows become columns and vice-versa\n",
        "null_df = null_df.T.astype(int)\n",
        "\n",
        "print(null_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             unique_key  date  ...  cause_vehicle_4  cause_vehicle_5\n",
            "null_counts           0     0  ...            57111            57671\n",
            "null_pct              0     0  ...               98               99\n",
            "\n",
            "[2 rows x 26 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcMHjL8o318F"
      },
      "source": [
        "About a third of the columns have no null values, with the rest ranging from less than 1% to 99%!\n",
        "\n",
        "To make things easier, let's start by looking at the group of columns that relate to people killed in collisions.\n",
        "\n",
        "We'll use list comprehension to reduce our summary dataframe to just those columns:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsG_L7kjfGEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f1083a-8d4a-471f-dbfa-8895c6fff6d2"
      },
      "source": [
        "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
        "print(null_df[killed_cols])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             pedestrians_killed  cyclist_killed  motorist_killed  total_killed\n",
            "null_counts                   0               0                0             5\n",
            "null_pct                      0               0                0             0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYTGQjkSfLCO"
      },
      "source": [
        "We can see that each of the individual categories have no missing values, but the `total_killed` column has five missing values.\n",
        "\n",
        "One option for handling this would be to remove – or drop – those five rows. This would be a reasonably valid choice since it's a tiny portion of the data, but let's think about what other options we have first.\n",
        "\n",
        "If you think about it, the total number of people killed should be the sum of each of the individual categories. We might be able to \"fill in\" the missing values with the sums of the individual columns for that row. The technical name for filling in a missing value with a replacement value is called **imputation**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd-8ID9dfRPt"
      },
      "source": [
        "Let's look at how we could explore the values where the `total_killed` isn't equal to the sum of the other three columns. We'll illustrate this process using a series of diagrams. The diagrams won't contain values, they'll just show a grid to represent the values.\n",
        "\n",
        "Let's start with a dataframe of just the four columns relating to people killed:\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_1.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkQ323CEfjcH"
      },
      "source": [
        "We then select just the first three columns, and manually sum each row:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_2.svg)\n",
        "\n",
        "We then compare the manual sum to the original total column to create a boolean mask where equivalent values are *not* equal:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_3.svg)\n",
        "\n",
        "Lastly, we use the boolean mask to filter the original dataframe to include only rows where the manual sum and original aren't equal:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/verify_totals_4.svg)\n",
        "\n",
        "Let's use this strategy to look at the rows that don't match up!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO_slk6_fz3K"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We created a dataframe `killed`, containing the five columns that relate to people killed in collisions.\n",
        "\n",
        "1. Select the first three columns from `killed` and sum each row. Assign the result to `killed_manual_sum`.\n",
        "2. Create a boolean mask that checks whether each value in `killed_manual_sum` is not equal to the values in the `total_killed` column. Assign the boolean mask to `killed_mask`.\n",
        "3. Use `killed_mask` to filter the rows in `killed`. Assign the result to `killed_non_eq`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia7UF6e4f1BP"
      },
      "source": [
        "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
        "killed = mvc[killed_cols].copy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10x3XqHHf2AV"
      },
      "source": [
        "### Part of the solution to make the next chapter work\n",
        "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
        "killed = mvc[killed_cols].copy()\n",
        "killed_manual_sum = killed.iloc[:,:3].sum(axis=1)\n",
        "killed_mask = killed_manual_sum != killed['total_killed']\n",
        "killed_non_eq = killed[killed_mask]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS_B2Wq43ZTD"
      },
      "source": [
        "## 3. Filling and Verifying the Killed and Injured Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ha8jIZl3ZVq"
      },
      "source": [
        "The `killed_non_eq` dataframe we created in the previous exercise contained six rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "FIXlQ2pMC7eb",
        "outputId": "fcc3fd13-10e9-47a3-cc19-ca8f1b91ba4b"
      },
      "source": [
        "killed_non_eq.head(6)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pedestrians_killed</th>\n",
              "      <th>cyclist_killed</th>\n",
              "      <th>motorist_killed</th>\n",
              "      <th>total_killed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3508</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20163</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22046</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48719</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55148</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55699</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pedestrians_killed  cyclist_killed  motorist_killed  total_killed\n",
              "3508                    0               0                0           NaN\n",
              "20163                   0               0                0           NaN\n",
              "22046                   0               0                1           0.0\n",
              "48719                   0               0                0           NaN\n",
              "55148                   0               0                0           NaN\n",
              "55699                   0               0                0           NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg7IJfOcC_9q"
      },
      "source": [
        "We can categorize these into two categories:\n",
        "\n",
        "1. Five rows where the `total_killed` is not equal to the sum of the other columns because the total value is missing.\n",
        "2. One row where the `total_killed` is less than the sum of the other columns.\n",
        "\n",
        "From this, we can conclude that filling null values with the sum of the columns is a fairly good choice for our imputation, given that only six rows out of around 58,000 don't match this pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLRXkuSGDUBx"
      },
      "source": [
        "We've also identified a row that has suspicious data - one that doesn't sum correctly. Once we have imputed values for all rows with missing values for `total_killed`, we'll mark this suspect row by setting its value to `NaN`.\n",
        "\n",
        "In order to execute this, we'll learn to use the `Series.mask()` [method](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.mask.html). `Series.mask()` is useful when you want to replace certain values in a series based off a boolean mask. The syntax for the method is:\n",
        "\n",
        "```\n",
        "Series.mask(bool_mask, val_to_replace)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9-Fg2PH9Ffv"
      },
      "source": [
        "Let's look at an example with some simple data. We'll start with a series called `fruits`:\n",
        "![img](https://s3.amazonaws.com/dq-content/370/mask_1.svg)\n",
        "\n",
        "Next, we create a boolean series that matches values equal to the string `Banana`:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/mask_2.svg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGm2KYgf_xB2"
      },
      "source": [
        "Lastly, we use `Series.mask()` to replace all the values that match the boolean series with a new value, `Pear`:\n",
        "![img](https://s3.amazonaws.com/dq-content/370/mask_3.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faCSgFjX_48a"
      },
      "source": [
        "If we wanted to describe the logic of the code above, we'd say *For each value in the \"fruits\" series, if the corresponding value in the \"bool\" series is true, update the value to \"Pear,\" otherwise leave the original value.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkYY0Ga8_8QZ"
      },
      "source": [
        "In the first example above, we updated a single value, but we can also update with the matching value from a series that has identical index labels, like this `nums` series:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/370/mask_4.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z1RrgudAE8l"
      },
      "source": [
        "Let's look at how we can update the matching values in `fruit` with the corresponding values in `nums`:\n",
        "![img](https://s3.amazonaws.com/dq-content/370/mask_5.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK39LmxYAlfP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VghEIrKK3ZX3"
      },
      "source": [
        "## 4. Assigning the Corrected Data Back to the Main Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8j4pinE3ZhG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS8po7Uc3ZmS"
      },
      "source": [
        "## 5. Visualizing Missing Data with Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDP4EJ1Q3Zpz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_jLG9343Zsz"
      },
      "source": [
        "## 6. Analyzing Correlations in Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA88kToh3Zv8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58lresB53Zz1"
      },
      "source": [
        "## 7. Finding the Most Common Values Across Multiple Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qtRs7jM3Z3I"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMAeYu3c3Z7M"
      },
      "source": [
        "## 8. Filling Unknown Values with a Placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTIoZKUG3Z_F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ66Zvek3aDE"
      },
      "source": [
        "## 9. Missing Data in the \"Location\" Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zQcQWgX3aJc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x68M_JvG3l_Q"
      },
      "source": [
        "## 10. Imputing Location Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY0zriW-3n2u"
      },
      "source": [
        ""
      ]
    }
  ]
}