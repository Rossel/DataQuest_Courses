{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "032__Working_With_Strings_In_Pandas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLYMVFrA4GSRRczmZF520u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rossel/DataQuest_Courses/blob/master/032__Working_With_Strings_In_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PWQ-EVGT2s_"
      },
      "source": [
        "# COURSE 4/6: DATA CLEANING AND ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THaX315BT2wD"
      },
      "source": [
        "# MISSION 4: Working With Strings In Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqvHISHhhbIr"
      },
      "source": [
        "Learn how to work with strings in pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQBrAPM9JEko"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHAC_2ZBGvIq"
      },
      "source": [
        "In the previous mission, we learned how to use the `apply()`, `map()`, and `applymap()` methods to apply a function to a series. While we could certainly use these methods to clean strings in columns, pandas has built in many vectorized string methods that can perform these tasks quicker and with less keystrokes.\n",
        "\n",
        "We introduced some of these methods already in the Pandas Fundamentals course when we learned the following data cleaning tasks:\n",
        "\n",
        "Cleaning column names\n",
        "Extracting values from the start of strings\n",
        "Extracting values from the end of strings\n",
        "In this mission, we'll learn a couple other string cleaning tasks such as:\n",
        "\n",
        "Finding specific strings or substrings in columns\n",
        "Extracting substrings from unstructured data\n",
        "Removing strings or substrings from a series\n",
        "As we learn these tasks, we'll also work to build intuition around how these string methods operate so that you can explore methods we haven't explicitly covered on your own.\n",
        "\n",
        "We'll work with the 2015 World Happiness Report again and additional economic data from the World Bank. You can find the data set here. Here's a preview of the data set:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[World Happiness Report](https://www.kaggle.com/unsdsn/world-happiness)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx4vKeuxNWig",
        "outputId": "432f785e-2ee3-48f2-8e95-0c0e75d6740a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# Import files directly using Google Colab\n",
        "# Download the files from the links below:\n",
        "# World_Happiness_2015.csv: https://drive.google.com/file/d/1iZ8_lHkMx7pI22s4ECfpNHKnOohyPfvU/view?usp=sharing\n",
        "\n",
        "from google.colab import files\n",
        "upload = files.upload()\n",
        "upload = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1864f1e2-34a5-4d94-8e89-9835d23dcba1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1864f1e2-34a5-4d94-8e89-9835d23dcba1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving World_Happiness_2015.csv to World_Happiness_2015.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40bb20bd-5656-4dc1-8302-c525e9a4751f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-40bb20bd-5656-4dc1-8302-c525e9a4751f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving World_dev.csv to World_dev.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RblOqgYLi5Uu"
      },
      "source": [
        "# Import pandas and numpy libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-13RwLZHNwum"
      },
      "source": [
        " # Read the csv files\n",
        " happiness2015 = pd.read_csv(\"World_Happiness_2015.csv\")\n",
        " world_dev = pd.read_csv(\"World_dev.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y46pZghDH81R",
        "outputId": "700ebf39-80db-41df-813b-890defb64456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "happiness2015.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Happiness Rank</th>\n",
              "      <th>Happiness Score</th>\n",
              "      <th>Standard Error</th>\n",
              "      <th>Economy (GDP per Capita)</th>\n",
              "      <th>Family</th>\n",
              "      <th>Health (Life Expectancy)</th>\n",
              "      <th>Freedom</th>\n",
              "      <th>Trust (Government Corruption)</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Dystopia Residual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Switzerland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>1</td>\n",
              "      <td>7.587</td>\n",
              "      <td>0.03411</td>\n",
              "      <td>1.39651</td>\n",
              "      <td>1.34951</td>\n",
              "      <td>0.94143</td>\n",
              "      <td>0.66557</td>\n",
              "      <td>0.41978</td>\n",
              "      <td>0.29678</td>\n",
              "      <td>2.51738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iceland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>2</td>\n",
              "      <td>7.561</td>\n",
              "      <td>0.04884</td>\n",
              "      <td>1.30232</td>\n",
              "      <td>1.40223</td>\n",
              "      <td>0.94784</td>\n",
              "      <td>0.62877</td>\n",
              "      <td>0.14145</td>\n",
              "      <td>0.43630</td>\n",
              "      <td>2.70201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Denmark</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>3</td>\n",
              "      <td>7.527</td>\n",
              "      <td>0.03328</td>\n",
              "      <td>1.32548</td>\n",
              "      <td>1.36058</td>\n",
              "      <td>0.87464</td>\n",
              "      <td>0.64938</td>\n",
              "      <td>0.48357</td>\n",
              "      <td>0.34139</td>\n",
              "      <td>2.49204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Norway</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>4</td>\n",
              "      <td>7.522</td>\n",
              "      <td>0.03880</td>\n",
              "      <td>1.45900</td>\n",
              "      <td>1.33095</td>\n",
              "      <td>0.88521</td>\n",
              "      <td>0.66973</td>\n",
              "      <td>0.36503</td>\n",
              "      <td>0.34699</td>\n",
              "      <td>2.46531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canada</td>\n",
              "      <td>North America</td>\n",
              "      <td>5</td>\n",
              "      <td>7.427</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>1.32629</td>\n",
              "      <td>1.32261</td>\n",
              "      <td>0.90563</td>\n",
              "      <td>0.63297</td>\n",
              "      <td>0.32957</td>\n",
              "      <td>0.45811</td>\n",
              "      <td>2.45176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Country          Region  ...  Generosity  Dystopia Residual\n",
              "0  Switzerland  Western Europe  ...     0.29678            2.51738\n",
              "1      Iceland  Western Europe  ...     0.43630            2.70201\n",
              "2      Denmark  Western Europe  ...     0.34139            2.49204\n",
              "3       Norway  Western Europe  ...     0.34699            2.46531\n",
              "4       Canada   North America  ...     0.45811            2.45176\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5D35NDWi65j"
      },
      "source": [
        "Below are descriptions for the columns we'll be working with:\n",
        "\n",
        "- `ShortName` - Name of the country\n",
        "- `Region` - The region the country belongs to\n",
        "- `IncomeGroup` - The income group the country belongs to, based on Gross National Income (GNI) per capita\n",
        "- `CurrencyUnit` - Name of country's currency\n",
        "- `SourceOfMostRecentIncomeAndExpenditureData` - The name of the survey used to collect the income and expenditure data\n",
        "- `SpecialNotes` - Contains any miscellaneous notes about the data\n",
        "\n",
        "To start, let's read the data sets into pandas and combine them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKgIgGgJh7tG"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We've already read `World_Happiness_2015.csv` into a dataframe called `happiness2015` and `World_dev.csv` into a dataframe called `world_dev`.\n",
        "\n",
        "- Use the `pd.merge()` function to combine `happiness2015` and `world_dev`. Save the resulting dataframe to `merged`. As a reminder, you can use the following syntax to combine the dataframes: `pd.merge(left=df1, right=df2, how='left', left_on='left_df_Column_Name', right_on='right_df_Column_Name')`.\n",
        " - Set the `left_on` parameter to the `Country` column from `happiness2015` and the `right_on` parameter to the `ShortName` column from `world_dev`.\n",
        "- Use the `DataFrame.rename()` [method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) to rename the `SourceOfMostRecentIncomeAndExpenditureData` column in `merged` to `IESurvey` (because we don't want to keep typing that long name!).\n",
        " - We've already saved the mapping to a dictionary named `col_renaming`.\n",
        " - Make sure to set the `axis` parameter to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss_e8nd6krfA"
      },
      "source": [
        "world_dev = pd.read_csv(\"World_dev.csv\")\n",
        "col_renaming = {'SourceOfMostRecentIncomeAndExpenditureData': 'IESurvey'}\n",
        "merged = pd.merge(left=happiness2015, right=world_dev, how='left', left_on='Country', right_on='ShortName')\n",
        "merged = merged.rename(col_renaming, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggZS1YtUh7wC"
      },
      "source": [
        "## 2. Using Apply to Transform Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-jXJGMh7y-"
      },
      "source": [
        "In the last step, we combined `happiness2015` and `world_dev` and assigned the result to `merged`. Below are the first five rows of `merged` (after removing some of the columns we don't need)(check with DQ page):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqtUuLBYfElI",
        "outputId": "13c62104-4b1d-4efa-f5b5-41109cc1590b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "merged.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region_x</th>\n",
              "      <th>Happiness Rank</th>\n",
              "      <th>Happiness Score</th>\n",
              "      <th>Standard Error</th>\n",
              "      <th>Economy (GDP per Capita)</th>\n",
              "      <th>Family</th>\n",
              "      <th>Health (Life Expectancy)</th>\n",
              "      <th>Freedom</th>\n",
              "      <th>Trust (Government Corruption)</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Dystopia Residual</th>\n",
              "      <th>CountryCode</th>\n",
              "      <th>ShortName</th>\n",
              "      <th>TableName</th>\n",
              "      <th>LongName</th>\n",
              "      <th>Alpha2Code</th>\n",
              "      <th>CurrencyUnit</th>\n",
              "      <th>SpecialNotes</th>\n",
              "      <th>Region_y</th>\n",
              "      <th>IncomeGroup</th>\n",
              "      <th>Wb2Code</th>\n",
              "      <th>NationalAccountsBaseYear</th>\n",
              "      <th>NationalAccountsReferenceYear</th>\n",
              "      <th>SnaPriceValuation</th>\n",
              "      <th>LendingCategory</th>\n",
              "      <th>OtherGroups</th>\n",
              "      <th>SystemOfNationalAccounts</th>\n",
              "      <th>AlternativeConversionFactor</th>\n",
              "      <th>PppSurveyYear</th>\n",
              "      <th>BalanceOfPaymentsManualInUse</th>\n",
              "      <th>ExternalDebtReportingStatus</th>\n",
              "      <th>SystemOfTrade</th>\n",
              "      <th>GovernmentAccountingConcept</th>\n",
              "      <th>ImfDataDisseminationStandard</th>\n",
              "      <th>LatestPopulationCensus</th>\n",
              "      <th>LatestHouseholdSurvey</th>\n",
              "      <th>IESurvey</th>\n",
              "      <th>VitalRegistrationComplete</th>\n",
              "      <th>LatestAgriculturalCensus</th>\n",
              "      <th>LatestIndustrialData</th>\n",
              "      <th>LatestTradeData</th>\n",
              "      <th>LatestWaterWithdrawalData</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Switzerland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>1</td>\n",
              "      <td>7.587</td>\n",
              "      <td>0.03411</td>\n",
              "      <td>1.39651</td>\n",
              "      <td>1.34951</td>\n",
              "      <td>0.94143</td>\n",
              "      <td>0.66557</td>\n",
              "      <td>0.41978</td>\n",
              "      <td>0.29678</td>\n",
              "      <td>2.51738</td>\n",
              "      <td>CHE</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>CH</td>\n",
              "      <td>Swiss franc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Europe &amp; Central Asia</td>\n",
              "      <td>High income: OECD</td>\n",
              "      <td>CH</td>\n",
              "      <td>Original chained constant price data are resca...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Value added at basic prices (VAB)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Country uses the 2008 System of National Accou...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rolling</td>\n",
              "      <td>IMF Balance of Payments Manual, 6th edition.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Special trade system</td>\n",
              "      <td>Consolidated central government</td>\n",
              "      <td>Special Data Dissemination Standard (SDDS)</td>\n",
              "      <td>2010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Expenditure survey/budget survey (ES/BS), 2004</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2008</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iceland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>2</td>\n",
              "      <td>7.561</td>\n",
              "      <td>0.04884</td>\n",
              "      <td>1.30232</td>\n",
              "      <td>1.40223</td>\n",
              "      <td>0.94784</td>\n",
              "      <td>0.62877</td>\n",
              "      <td>0.14145</td>\n",
              "      <td>0.43630</td>\n",
              "      <td>2.70201</td>\n",
              "      <td>ISL</td>\n",
              "      <td>Iceland</td>\n",
              "      <td>Iceland</td>\n",
              "      <td>Republic of Iceland</td>\n",
              "      <td>IS</td>\n",
              "      <td>Iceland krona</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Europe &amp; Central Asia</td>\n",
              "      <td>High income: OECD</td>\n",
              "      <td>IS</td>\n",
              "      <td>Original chained constant price data are resca...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Value added at basic prices (VAB)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Country uses the 2008 System of National Accou...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rolling</td>\n",
              "      <td>IMF Balance of Payments Manual, 6th edition.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>General trade system</td>\n",
              "      <td>Consolidated central government</td>\n",
              "      <td>Special Data Dissemination Standard (SDDS)</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Integrated household survey (IHS), 2010</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2010</td>\n",
              "      <td>2005.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2005.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Denmark</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>3</td>\n",
              "      <td>7.527</td>\n",
              "      <td>0.03328</td>\n",
              "      <td>1.32548</td>\n",
              "      <td>1.36058</td>\n",
              "      <td>0.87464</td>\n",
              "      <td>0.64938</td>\n",
              "      <td>0.48357</td>\n",
              "      <td>0.34139</td>\n",
              "      <td>2.49204</td>\n",
              "      <td>DNK</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>Kingdom of Denmark</td>\n",
              "      <td>DK</td>\n",
              "      <td>Danish krone</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Europe &amp; Central Asia</td>\n",
              "      <td>High income: OECD</td>\n",
              "      <td>DK</td>\n",
              "      <td>Original chained constant price data are resca...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Value added at basic prices (VAB)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Country uses the 2008 System of National Accou...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rolling</td>\n",
              "      <td>IMF Balance of Payments Manual, 6th edition.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Special trade system</td>\n",
              "      <td>Consolidated central government</td>\n",
              "      <td>Special Data Dissemination Standard (SDDS)</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Income tax registers (ITR), 2010</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Norway</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>4</td>\n",
              "      <td>7.522</td>\n",
              "      <td>0.03880</td>\n",
              "      <td>1.45900</td>\n",
              "      <td>1.33095</td>\n",
              "      <td>0.88521</td>\n",
              "      <td>0.66973</td>\n",
              "      <td>0.36503</td>\n",
              "      <td>0.34699</td>\n",
              "      <td>2.46531</td>\n",
              "      <td>NOR</td>\n",
              "      <td>Norway</td>\n",
              "      <td>Norway</td>\n",
              "      <td>Kingdom of Norway</td>\n",
              "      <td>NO</td>\n",
              "      <td>Norwegian krone</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Europe &amp; Central Asia</td>\n",
              "      <td>High income: OECD</td>\n",
              "      <td>NO</td>\n",
              "      <td>Original chained constant price data are resca...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Value added at basic prices (VAB)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Country uses the 2008 System of National Accou...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rolling</td>\n",
              "      <td>IMF Balance of Payments Manual, 6th edition.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>General trade system</td>\n",
              "      <td>Consolidated central government</td>\n",
              "      <td>Special Data Dissemination Standard (SDDS)</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Income survey (IS), 2010</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canada</td>\n",
              "      <td>North America</td>\n",
              "      <td>5</td>\n",
              "      <td>7.427</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>1.32629</td>\n",
              "      <td>1.32261</td>\n",
              "      <td>0.90563</td>\n",
              "      <td>0.63297</td>\n",
              "      <td>0.32957</td>\n",
              "      <td>0.45811</td>\n",
              "      <td>2.45176</td>\n",
              "      <td>CAN</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Canada</td>\n",
              "      <td>CA</td>\n",
              "      <td>Canadian dollar</td>\n",
              "      <td>Fiscal year end: March 31; reporting period fo...</td>\n",
              "      <td>North America</td>\n",
              "      <td>High income: OECD</td>\n",
              "      <td>CA</td>\n",
              "      <td>Original chained constant price data are resca...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Value added at basic prices (VAB)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Country uses the 2008 System of National Accou...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011</td>\n",
              "      <td>IMF Balance of Payments Manual, 6th edition.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>General trade system</td>\n",
              "      <td>Consolidated central government</td>\n",
              "      <td>Special Data Dissemination Standard (SDDS)</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Labor force survey (LFS), 2010</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2011</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>1986.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Country        Region_x  ...  LatestTradeData  LatestWaterWithdrawalData\n",
              "0  Switzerland  Western Europe  ...           2013.0                     2000.0\n",
              "1      Iceland  Western Europe  ...           2013.0                     2005.0\n",
              "2      Denmark  Western Europe  ...           2013.0                     2009.0\n",
              "3       Norway  Western Europe  ...           2013.0                     2006.0\n",
              "4       Canada   North America  ...           2013.0                     1986.0\n",
              "\n",
              "[5 rows x 43 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MefVCoHYfXBv"
      },
      "source": [
        "Let's work with the `CurrencyUnit` column first. Suppose we wanted to extract the unit of currency without the leading nationality. For example, instead of \"Danish krone\" or \"Norwegian krone\", we just needed \"krone\".\n",
        "\n",
        "If we wanted to complete this task for just one of the strings, we could use Python's `tring.split()` [method](https://docs.python.org/3/library/stdtypes.html):\n",
        "```\n",
        "words = 'Danish krone'\n",
        "\n",
        "#Use the string.split() method to return the following list: ['Danish', 'krone']\n",
        "listwords = words.split()\n",
        "\n",
        "#Use the index -1 to return the last word of the list.\n",
        "listwords[-1]\n",
        "```\n",
        "Now, to repeat this task for each element in the Series, let's return to a concept we learned in the previous mission - the `Series.apply()` [method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM0agYFhf0oa"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "- Write a function called `extract_last_word` with the following criteria:\n",
        " - The function should accept one parameter called `element`.\n",
        " - Use the `string.split()` method to split the object into a list. First convert `element` to a string as follows: `str(element)`.\n",
        " - Return the last word of the list.\n",
        "- Use the `Series.apply()` method to apply the function to the `CurrencyUnit` column. Save the result to `merged['Currency Apply']`.\n",
        "- Use the `Series.head()` method to print the first five rows in `merged['Currency Apply']`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVxfeacvgP8a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJvFGXbzh72I"
      },
      "source": [
        "## 3. Vectorized String Methods Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9FUInO9h75u"
      },
      "source": [
        "In the last exercise, we extracted the last word of each element in the `CurrencyUnit` column using the `Series.apply()` method. However, we also learned in the last mission that we should use built-in vectorized methods (if they exist) instead of the `Series.apply()` method for performance reasons.\n",
        "\n",
        "Instead, we could've split each element in the `CurrencyUnit` column into a list of strings with the `Series.str.split()` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.split.html), the vectorized equivalent of Python's `string.split()` method:\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Split.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_y9UaFlJZ57"
      },
      "source": [
        "In fact, pandas has built in a number of vectorized methods that perform the same operations for strings in series as Python string methods.\n",
        "\n",
        "Below are some common vectorized string methods, but you can find the full list [here](https://pandas.pydata.org/pandas-docs/stable/text.html#method-summary):\n",
        "\n",
        "|Method|Description|\n",
        "|---|---|\n",
        "|Series.str.split()|\tSplits each element in the Series.|\n",
        "|Series.str.strip()\t|Strips whitespace from each string in the Series.|\n",
        "|Series.str.lower()\t|Converts strings in the Series to lowercase.|\n",
        "|Series.str.upper()\t|Converts strings in the Series to uppercase.|\n",
        "|Series.str.get()\t|Retrieves the ith element of each element in the Series.|\n",
        "|Series.str.replace()\t|Replaces a regex or string in the Series with another string.|\n",
        "|Series.str.cat()\t|Concatenates strings in a Series.|\n",
        "|Series.str.extract()\t|Extracts substrings from the Series matching a regex pattern.|\n",
        "\n",
        "We access these vectorized string methods by adding a `str` between the Series name and method name:\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Syntax.png)\n",
        "\n",
        "The `str` attribute indicates that each object in the Series should be treated as a string, without us having to explicitly change the type to a string like we did when using the `apply` method.\n",
        "\n",
        "Note that we can also slice each element in the Series to extract characters, but we'd still need to use the `str` attribute. For example, below we access the first five characters in each element of the `CurrencyUnit` column:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90u3FISxKKXg",
        "outputId": "9a9e2ba7-fb2b-458d-d8d1-3298eff6cf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "merged['CurrencyUnit'].str[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Swiss\n",
              "1      Icela\n",
              "2      Danis\n",
              "3      Norwe\n",
              "4      Canad\n",
              "       ...  \n",
              "153    Rwand\n",
              "154    West \n",
              "155      NaN\n",
              "156    Burun\n",
              "157    West \n",
              "Name: CurrencyUnit, Length: 158, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZI9xsPMKidM"
      },
      "source": [
        "It's also good to know that vectorized string methods can be chained. For example, suppose we needed to split each element in the `CurrencyUnit` column into a list of strings using the `Series.str.split()` method and capitalize the letters using the `Series.str.upper()` method. You can use the following syntax to apply more than one method at once:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a86oRsHaKngM",
        "outputId": "a7785f23-da6e-47ba-8a3f-ef3bab5ba96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "merged['CurrencyUnit'].str.upper().str.split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   [SWISS, FRANC]\n",
              "1                 [ICELAND, KRONA]\n",
              "2                  [DANISH, KRONE]\n",
              "3               [NORWEGIAN, KRONE]\n",
              "4               [CANADIAN, DOLLAR]\n",
              "                  ...             \n",
              "153               [RWANDAN, FRANC]\n",
              "154    [WEST, AFRICAN, CFA, FRANC]\n",
              "155                            NaN\n",
              "156               [BURUNDI, FRANC]\n",
              "157    [WEST, AFRICAN, CFA, FRANC]\n",
              "Name: CurrencyUnit, Length: 158, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YenWDzm8KwDv"
      },
      "source": [
        "However, don't forget to include `str` before each method name, or you'll get an error!\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "- Use the `Series.str.split()` method to split the `CurrencyUnit` column into a list of words and then use the `Series.str.get()` method to select just the last word. Assign the result to `merged['Currency Vectorized']`.\n",
        "- Use the `Series.head()` method to print the first five rows in `merged['Currency Vectorized']`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRWejGDTK_vS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwwTDCI7h79k"
      },
      "source": [
        "## 4. Exploring Missing Values with Vectorized String Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0apJpu4h8Ah"
      },
      "source": [
        "We learned that using vectorized string methods results in:\n",
        "\n",
        "1. Better performance\n",
        "2. Code that is easier to read and write\n",
        "\n",
        "Let's explore another benefit of using vectorized string methods next. Suppose we wanted to compute the length of each string in the `CurrencyUnit` column. If we use the `Series.apply()` method, what happens to the missing values in the column?\n",
        "\n",
        "First, let's use the `Series.isnull()` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isnull.html) to confirm if there are any missing values in the column:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sug8JxBsnCtm",
        "outputId": "6b8f9921-5e0c-49b8-a676-20bb5fa062ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "merged['CurrencyUnit'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_gC7RpmnS95"
      },
      "source": [
        "So, we know that the `CurrencyUnit` column has 13 missing values.\n",
        "\n",
        "Next, let's create a function to return the length of each currency unit and apply it to the `CurrencyUnit` column:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0PZV08MnXZu"
      },
      "source": [
        "def compute_lengths(element):\n",
        "    return len(str(element))\n",
        "lengths_apply = merged['CurrencyUnit'].apply(compute_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVhGkQfOnZO4"
      },
      "source": [
        "Then, we can check the number of missing values in the result by setting the `dropna` parameter in the `Series.value_counts()` method to False:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqFQTxj6nfxx",
        "outputId": "ee60e302-2038-4b6b-e4d5-d0f8fd1b8374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "lengths_apply.value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14    21\n",
              "4     20\n",
              "12    17\n",
              "13    14\n",
              "3     13\n",
              "15    13\n",
              "16    12\n",
              "18     9\n",
              "17     9\n",
              "11     8\n",
              "22     7\n",
              "25     5\n",
              "19     3\n",
              "9      2\n",
              "26     1\n",
              "20     1\n",
              "23     1\n",
              "10     1\n",
              "39     1\n",
              "Name: CurrencyUnit, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDE1BvBannV0"
      },
      "source": [
        "Since the original column had 13 missing values and *`NaN` doesn't appear in the list of unique values above*, we know our function must have treated `NaN` as a string and returned a length of `3` for each `NaN` value. This doesn't make sense - missing values shouldn't be treated as strings. They should instead have been *excluded* from the calculation.\n",
        "\n",
        "If we wanted to exclude missing values, we'd have to update our function to something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL70petXnxhA"
      },
      "source": [
        "def compute_lengths(element):\n",
        "    if pd.isnull(element):\n",
        "        pass\n",
        "    else:\n",
        "        return len(str(element))\n",
        "lengths_apply = merged['CurrencyUnit'].apply(compute_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDyTeTANn4AL"
      },
      "source": [
        "Let's confirm the behavior of pandas' vectorized string methods next.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "- Use the `Series.str.len()` method to return the length of each element in the `CurrencyUnit` column. Assign the result to `lengths`.\n",
        "- Use the `Series.value_counts()` method to return the count of unique values in `lengths`. Set the `dropna` parameter to False so `NaN`s are counted, too. Assign the result to `value_counts`.\n",
        " - If `value_counts` contains `NaN`s, it means the `Series.str.len()` method *excluded* them and didn't treat them as strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpBM1XmAoPv6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwkdblAWh8EC"
      },
      "source": [
        "## 5. Finding Specific Words in Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW1V10sph8Ir"
      },
      "source": [
        "In the last exercise, we identified a third benefit of using vectorized string methods - they exclude missing values:\n",
        "\n",
        "1. Better performance\n",
        "2. Code that is easier to read and write\n",
        "3. Automatically excludes missing values\n",
        "\n",
        "Now that we know the benefits of using vectorized string methods, let's practice using them for specific data cleaning tasks.\n",
        "\n",
        "Suppose we needed to parse the elements of a Series to find a string or substring that doesn't appear in the same position in each string. For example, let's look at the `SpecialNotes` column. A number of rows mention \"national accounts\", but the words appear in different places in each comment:\n",
        "```\n",
        "April 2013 database update: Based on IMF data, national accounts data were revised for 2000 onward; the **base year** changed to 2002.\n",
        "Based on IMF data, national accounts data have been revised for 2005 onward; the new base year is 2005.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p6kUQtyRB1i"
      },
      "source": [
        "If we wanted to determine how many comments contain this phrase, could we split them into lists? Since the formats are different, how could we tell which element contains the \"national accounts\" phrase?\n",
        "\n",
        "We can handle problems like this with regul**ar expressions**, or **regex** for short. A regular expression is a sequence of characters that describes a search pattern, used to match characters in a string:\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Regular_Expressions.png)\n",
        "\n",
        "In pandas, regular expression is integrated with vectorized string methods to make finding and extracting patterns of characters easier. However, the rules for creating regular expressions can be quite complex, so don't worry about memorizing them. In this mission, we'll provide guidance on how to create the regex we need to use for the exercises, but you can also follow along using this documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UqJygaqRbal"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We've already saved the regex to a variable called `pattern`. The brackets, `[]`, indicate that either \"national accounts\" or \"National accounts\" should produce a match.\n",
        "\n",
        "- Use the `Series.str.contains()` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.contains.html) to search for `pattern` in the `SpecialNotes` column. Assign the result to `national_accounts`.\n",
        "- Use the `Series.head()` method to print the first five rows in `national_accounts`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzx9TggoQ7Ei"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZk8xxnah8M-"
      },
      "source": [
        "## 6. Finding Specific Words in Strings Continued"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oor6577Gh8Qz"
      },
      "source": [
        "In the last screen, we used the `Series.str.contains()` method to see if a specific phrase appeared in a series. The result was a series containing `True`, `False`, and missing values:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxB653YqXZ--",
        "outputId": "27b13a78-e6c8-40e1-e106-f3215eb21df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "national_accounts = merged['SpecialNotes'].str.contains(r\"[Nn]ational accounts\")\n",
        "\n",
        "#Return the value counts for each value in the Series, including missing values.\n",
        "national_accounts.value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NaN      65\n",
              "True     54\n",
              "False    39\n",
              "Name: SpecialNotes, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0wH7XBLXbhc"
      },
      "source": [
        "Now, we should be able to use boolean indexing to return only the rows that contain \"national accounts\" or \"National accounts\" in the `SpecialNotes` column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFMaToF2Xu8f",
        "outputId": "7a433008-9f46-44d2-b574-c74f1deff196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "merged[national_accounts]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9c700c3b3679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnational_accounts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2892\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2893\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mna_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cannot mask with non-boolean array containing NA / NaN values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot mask with non-boolean array containing NA / NaN values"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "finc2G7JYNX-"
      },
      "source": [
        "It looks like we got an error now because of the `NaN` values! One way we could fix this is to change the `NaN` values to False in `national_accounts`.\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Missing_values.svg)\n",
        "\n",
        "Let's practice a way we can easily make this change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQXWvpTEYdBX"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "- Use the `Series.str.contains()` method to search for `pattern` in the `SpecialNotes` column again. This time, also pass in the `na` parameter and set it to False. Assign the result to `national_accounts`.\n",
        "- Use `national_accounts` to index `merged`, so that only rows that contain \"national accounts\" or \"National accounts\" in the `SpecialNotes` column are returned. Assign the result to `merged_national_accounts`.\n",
        "- Use the DataFrame.head() method to print the first five rows in `merged_national_accounts`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Pbi4BEZFR-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUQ_gHRAh8V5"
      },
      "source": [
        "## 7. Extracting Substrings from a Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pcR1kBYh8bD"
      },
      "source": [
        "In the last screen, we learned how to use regular expressions and the `Series.str.contains()` method to search for patterns of characters in a column and index the dataframe based on the matches. Let's continue exploring the versatility of regular expressions while learning a new task - extracting characters from strings.\n",
        "\n",
        "Suppose we wanted to extract any year mentioned in the `SpecialNotes` column. Notice that the characters in a year follow a specific pattern:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Years.png)\n",
        "\n",
        "The first digit can be either `1` or `2`, while the last three digits can be any number between `0` and `9`.\n",
        "\n",
        "With regular expressions, we use the following syntax to indicate a character could be a range of numbers:\n",
        "```\n",
        "pattern = r\"[0-9]\"\n",
        "```\n",
        "And we use the following syntax to indicate a character could be a range of letters:\n",
        "```\n",
        "#lowercase letters\n",
        "pattern1 = r\"[a-z]\"\n",
        "\n",
        "#uppercase letters\n",
        "pattern2 = r\"[A-Z]\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tanh3rv7VBiY"
      },
      "source": [
        "We could also make these ranges more restrictive. For example, if we wanted to find a three character substring in a column that starts with a number between 1 and 6 and ends with two letters of any kind, we could use the following syntax:\n",
        "```\n",
        "pattern = r\"[1-6][a-z][a-z]\"\n",
        "```\n",
        "If we have a pattern that repeats, we can also use curly brackets `{` and `}` to indicate the number of times it repeats:\n",
        "\n",
        "```\n",
        "pattern = r\"[1-6][a-z][a-z]\" = r\"[1-6][a-z]{2}\"\n",
        "```\n",
        "\n",
        "Let's explore the `Series.str.extract()` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.extract.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGyy4OMcViak"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "- Create a regular expression that will match years and assign it to the variable `pattern`. Note: we've already set up the `pattern` variable. Insert your answer inside the parantheses: `\"(your_answer)\"`.\n",
        "- Use `pattern` and the `Series.str.extract()` method to extract years from the `SpecialNotes` column. Assign the resulting Series to `years`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twBMXHX1Vu41"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPSkD1B9h8f4"
      },
      "source": [
        "## 8. Extracting Substrings from a Series Continued"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX9mE5sXh8lP"
      },
      "source": [
        "In the last exercise, we learned how to identify more complex patterns with regular expressions and extract substrings from a column using that pattern.\n",
        "\n",
        "When we used the `Series.str.extract()` method, we enclosed our regular expression in parentheses. The parentheses indicate that only the character pattern matched should be extracted and returned in a series. We call this a **capturing group**.\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Parantheses.png)\n",
        "\n",
        "If the capturing group doesn't exist in a row (or there is no match) the value in that row is set to `NaN` instead. As a result, the Series returned looked like this:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Extracting_Results.png)\n",
        "\n",
        "We can also return the results as a dataframe by changing the `expand` parameter to True.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq2kbfkkmkds"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "Use `pattern` and the `ΩSeries.str.extract()` method to extract years from the `SpecialNotes` column again, but this time, set the `expand` parameter to `True` to return the results as a dataframe. Assign the resulting dataframe to `years`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bi13cjzms8I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fkQ-lYRh8pw"
      },
      "source": [
        "## 9. Extracting All Matches of a Pattern from a Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipAGEgkDh8uB"
      },
      "source": [
        "In the last screen, we learned we could use the `Series.str.extract()` method to extract a pattern of characters from a column as a dataframe by setting the `expand` parameter equal to `True`. However, the `Series.str.extract()` method will only extract the *first* match of the pattern. If we wanted to extract all of the matches, we can use the `Series.str.extractall()` [method](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extractall.html).\n",
        "\n",
        "We'll demonstrate this method but, first, let's make the results easier to read by using the `df.set_index()` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html) to set the `Country` column as the index.\n",
        "\n",
        "```\n",
        "merged = merged.set_index('Country')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WEfGSNMep8H"
      },
      "source": [
        "Next, let's use the same regular expression from the last screen to extract all the years from the `Special Notes` column, except this time, we'll use a **named capturing group**. Using a named capturing group means that we can refer to the group by the specified name instead of just a number. We can use the following syntax to add a name: `(?P<Column_Name>...)`.\n",
        "\n",
        "Below, we name the capturing group `Years`:\n",
        "```\n",
        "pattern = r\"(?P<Years>[1-2][0-9]{3})\"\n",
        "merged['SpecialNotes'].str.extractall(pattern)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3ATxrpfGsb"
      },
      "source": [
        "Below are the first five rows of the output:\n",
        "[img](https://s3.amazonaws.com/dq-content/346/Extractall.png)\n",
        "Let's look at the `IESurvey` column next. This column has years in two different formats:\n",
        "```\n",
        "Integrated household survey (IHS), 2012\n",
        "Integrated household survey (IHS), 2010/11\n",
        "```\n",
        "Let's test the code above on this column to see if we can extract all of the years from the `IESurvey` column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD1ERLhnf5qx"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We've already set the `Country` column as the index and saved the regular expression used to extract years in the `pattern` variable.\n",
        "\n",
        "- Use the `Series.str.extractall()` method to extract all of the years in the `IESurvey`. Assign the result to `years`.\n",
        "- Use the `Series.value_counts()` method to create a list of the unique years, along with the count. Assign the result to `value_counts`. Print `value_counts`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksabdo3SgH_R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myDUqbWCh8y4"
      },
      "source": [
        "## 10. Extracting More Than One Group of Patterns from a Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cvv40Hth83w"
      },
      "source": [
        "When we tried to extract all of the years from the `IESurvey` column using the `extractall` method in the last exercise, we were unsuccessful because some of our years had the following format:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Years_updated.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYrscZIm_FJ0"
      },
      "source": [
        "Because our regular expression only accounted for the pattern highlighted below, we created a dataframe with just the first year in each row:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Years_first_group.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyBF9kBS_NUS"
      },
      "source": [
        "If we wanted to extract the second, abbreviated year, we'd have to specify two more groups - one to extract the `/` and one to extract the last two digits.\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Years_all_groups.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Nh28RA_Xdj"
      },
      "source": [
        "Let's add those two groups to our regex and try to extract them again:\n",
        "\n",
        "```\n",
        "pattern = r\"(?P<First_Year>[1-2][0-9]{3})(/)?(?P<Second_Year>[0-9]{2})?\"\n",
        "years = merged['IESurvey'].str.extractall(pattern)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2R7Vlj_nJ0"
      },
      "source": [
        "Note that we also added a question mark, `?`, after each of the two new groups to indicate that a match for those groups is optional. This allows us to extract years listed in the `yyyy` format AND the `yyyy/yy` format at once.\n",
        "\n",
        "Below are the first five rows:\n",
        "\n",
        "|..|\n",
        "|---|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih2GAxWw_1mF"
      },
      "source": [
        "If we sort the values, we can confirm that we also extracted years in the `yyyy/yy` format:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm-K_eHG_367"
      },
      "source": [
        "years.sort_values('Second_Year')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SIMtGbV_5wA"
      },
      "source": [
        "The dataframe returned has three columns - one for each capturing group specified in `pattern`. Because we didn't name the second group, `(/)`, the capturing group number, `1`, was used as the column name.\n",
        "\n",
        "In the next exercise, we'll extract just the years from the `IESurvey` column. Then, we'll reformat the second year so that it contains all four digits of the year, not just the last two, so that it looks like the dataframe below:\n",
        "\n",
        "|..|\n",
        "|---|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfVGLNzcAT7H"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "We've already created a regular expression that extracts the pattern \"yyyy/yy\" and saved it to a variable called `pattern`. Notice that we didn't enclose `/?` in parantheses so that the resulting dataframe will only contain a `First_Year` and `Second_Year` column.\n",
        "\n",
        "- Use the `Series.str.extractall()` method to extract `pattern` from the `IESurvey` column. Assign the result to `years`.\n",
        "- Use vectorized slicing to extract the first two numbers from the `First_Year` column in `years` (For example, extract \"20\" from \"2000\"). Assign the result to `first_two_year`.\n",
        "- Add `first_two_year` to the `Second_Year` column in `years`, so that `Second_Year` contains the full year (ex: \"2000\"). Assign the result to `years['Second_Year']`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m0W7leQAsMH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0P0u86bh89d"
      },
      "source": [
        "## 11. Challenge: Clean a String Column, Aggregate the Data, and Plot the Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSMj5q3Ph9C5"
      },
      "source": [
        "Let's summarize what we learned about the `Series.str.extractall()` method and pandas string operations in the last exercise:\n",
        "\n",
        "1. If part of the regex isn't grouped using parantheses, `()`, it won't be extracted.\n",
        "2. When we add a string to a column using the plus sign, `+`, pandas will add that string to every value in the column. Note that the strings will be added together without any spaces.\n",
        "\n",
        "Unfortunately, there are too many possible string cleaning tasks for us to review each one in detail. However, now that we have a general understanding of how string methods operate, we can apply our knowledge to tasks we haven't covered explicitly in this mission.\n",
        "\n",
        "Next, we'll group `merged` by the `IncomeGroup` column and plot the results. First, however, we would like to clean the values in the `IncomeGroup` column to a standardized format shown in the table below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzOUjETTh9Ih"
      },
      "source": [
        "|Current Values|Updated Values|\n",
        "|---|---|\n",
        "|Upper middle income|\tUPPER MIDDLE|\n",
        "|Lower middle income|\tLOWER MIDDLE\n",
        "|High income: OECD|\tHIGH OECD\n",
        "|Low income\t|LOW\n",
        "|High income: nonOECD\t|HIGH NONOECD\n",
        "\n",
        "After, we'll create a pivot table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0J7rPfHaqN4"
      },
      "source": [
        "pv_incomes = merged.pivot_table(values='Happiness Score', index='IncomeGroup')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeQ806sKa3ZJ"
      },
      "source": [
        "Finally, we'll plot the results as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwJBcwkfa6Lh"
      },
      "source": [
        "pv_incomes.plot(kind='bar', rot=30, ylim=(0,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMTM2KqOa8NR"
      },
      "source": [
        "The result should match the bar chart below:\n",
        "![img](https://s3.amazonaws.com/dq-content/346/Income_Plot.png)\n",
        "\n",
        "Let's use some of the vectorized string methods below to update the values in the `IncomeGroup` column next:\n",
        "\n",
        "|Method|\tDescription|\n",
        "|---|---|\n",
        "Series.str.split()|\tSplits each element in the Series.\n",
        "Series.str.strip()|\tStrips whitespace from each string in the Series.\n",
        "Series.str.lower()|\tConverts strings in the Series to lowercase.\n",
        "Series.str.upper()|\tConverts strings in the Series to uppercase.\n",
        "Series.str.get()|\tRetrieves the ith element of each element in the Series.\n",
        "Series.str.replace()|\tReplaces a regex or string in the Series with another string.\n",
        "Series.str.cat()|\tConcatenates strings in a Series.\n",
        "Series.str.extract()|\tExtracts substrings from the Series matching a regex pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFmh1HOxbcAa"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "As a reminder, we would like to clean the values in the `IncomeGroup` column to a standardized format shown in the table below.\n",
        "\n",
        "|Current Values |Updated Values\n",
        "|---|---|\n",
        "Upper middle income\t|UPPER MIDDLE\n",
        "Lower middle income\t|LOWER MIDDLE\n",
        "High income: OECD\t|HIGH OECD\n",
        "Low income\t|LOW\n",
        "High income: nonOECD\t|HIGH NONOECD\n",
        "\n",
        "- Use some of the string methods above to clean the `IncomeGroup` column.\n",
        " - Make sure to remove the whitespace at the end of the strings.\n",
        "- Use the `df.pivot_table()` method to return the mean of each income group in the `IncomeGroup` column. Set the `index` parameter equal to the `IncomeGroup` column and the `values` parameter equal to the `Happiness Score` column. Assign the result to `pv_incomes`.\n",
        "- Use the `df.plot()` method to plot the results. Set the `kind` parameter equal to `bar`, the `rot` parameter equal to `30`, and the `ylim` parameter equal to `(0,10)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5wT56WAeYQd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Br3Etae0Sx"
      },
      "source": [
        "---\n",
        "In this mission, we explored the benefits of using vectorized string methods, along with a couple methods that can be used to perform tasks such as finding substrings, extracting substrings, and removing substrings from columns. You can find the full list of vectorized string methods [here](https://pandas.pydata.org/pandas-docs/stable/text.html#method-summary). We encourage you to explore more string methods or string cleaning tasks independently.\n",
        "\n",
        "In the next mission, we'll return to another important data cleaning task - how to handle missing values."
      ]
    }
  ]
}