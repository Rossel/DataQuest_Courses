{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "034__Working_With_Missing_And_Duplicate_Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNE6LQXbjmt+cSQf3eruEix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rossel/DataQuest_Courses/blob/master/034__Working_With_Missing_And_Duplicate_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PWQ-EVGT2s_"
      },
      "source": [
        "# COURSE 5/6: DATA CLEANING IN PYTHON: ADVANCED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THaX315BT2wD"
      },
      "source": [
        "# MISSION 1: Regular Expression Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqvHISHhhbIr"
      },
      "source": [
        "Learn to perform data cleaning with regular expressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQBrAPM9JEko"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MccUxipEGucJ"
      },
      "source": [
        "In the previous course, we learned that regular expressions are a powerful way of building patterns to match text. In the first two missions of this Data Cleaning Advanced course, we're going to extend our knowledge about this extremely powerful tool that every data scientist should be familiar with.\n",
        "\n",
        "As powerful as regular expressions are, they can be difficult to learn at first and the syntax can look visually intimidating. As a result, a lot of students end up disliking regular expressions and try to avoid using them, instead opting to write more cumbersome code.\n",
        "\n",
        "![IMG](https://s3.amazonaws.com/dq-content/354/difficult_regex_v2.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCX35jf-HZ1E"
      },
      "source": [
        "That said, learning (and loving!) regular expressions is something that is a worthwhile investment\n",
        "\n",
        "- Once you understand how they work, complex operations with string data can be written a lot quicker, which will save you time.\n",
        "- Regular expressions are often faster to execute than their manual equivalents.\n",
        "- Regular expressions are supported in almost every modern programming language, as well as other places like command line utilities and databases. Understanding regular expressions gives you a powerful tool that you can use wherever you work with data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzVPxrStHiqk"
      },
      "source": [
        "We could probably fill a whole Dataquest course with the intricacies of regular expressions, but instead we're going to give you a two-mission tour of the main components.\n",
        "\n",
        "One thing to keep in mind before we start: don't expect to remember all of the regular expression syntax. The most important thing is to understand the core principles, what is possible, and where to look up the details. This will mean you can quickly jog your memory whenever you need regular expressions.\n",
        "\n",
        "With that in mind, don't be put off if some things in these missions don't stick in your memory. As long as you are able to write and understand regular expressions with the help of documentation and/or other reference guides, you have all the skills you need to excel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rEaBapnuPBC"
      },
      "source": [
        "We'll be learning regular expressions while performing analysis on a dataset of submissions to popular technology site [Hacker News](https://news.ycombinator.com/).\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/354/hacker_news.jpg)\n",
        "\n",
        "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"stories\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles; stories that make it to the top of Hacker News' listings can get hundreds of thousands of visitors.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBGGmrPXuYgV"
      },
      "source": [
        "The dataset we will be working with is based off [this CSV of Hacker News stories from September 2015 to September 2016](). The columns in the dataset are explained below:\n",
        "\n",
        "- `id`: The unique identifier from Hacker News for the story\n",
        "- `title`: The title of the story\n",
        "- `url`: The URL that the stories links to, if the story has a URL\n",
        "- `num_points`: The number of points the story acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
        "- `num_comments`: The number of comments that were made on the story\n",
        "- `author`: The username of the person who submitted the story\n",
        "- `created_at`: The date and time at which the story was submitted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDxxZkuGuvZm"
      },
      "source": [
        "For teaching purposes, we have reduced the dataset from the almost 300,000 rows in its original form to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. You can download the modified dataset using the dataset preview tool.\n",
        "\n",
        "Let's start by reading our Hacker News dataset into a pandas dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR_huuJMuz9t"
      },
      "source": [
        ""
      ]
    }
  ]
}