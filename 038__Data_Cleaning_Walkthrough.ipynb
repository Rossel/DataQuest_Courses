{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "038__Data_Cleaning_Walkthrough.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWZceKx0jUyCR/fyuoN/Qf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rossel/DataQuest_Courses/blob/master/038__Data_Cleaning_Walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PWQ-EVGT2s_"
      },
      "source": [
        "# COURSE 5/6: DATA CLEANING IN PYTHON: ADVANCED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgjiYKzEU1Px"
      },
      "source": [
        "# MISSION 1:Data Cleaning Walkthrough\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpILlKG5VBwg"
      },
      "source": [
        "Learn how to explore and clean multiple data files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfk12M-4TwZU"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n8U5XcG9MHu"
      },
      "source": [
        "At many points in your career, you'll need to be able to build complete, end-to-end data science projects on your own. Data science projects usually consist of one of two things:\n",
        "\n",
        "- An exploration and analysis of a set of data. One example might involve analyzing donors to political campaigns, creating a plot, and then sharing an analysis of the plot with others.\n",
        "- An operational system that generates predictions based on data that updates continually. An algorithm that pulls in daily stock ticker data and predicts which stock prices will rise and fall would be one example.\n",
        "\n",
        "You'll find the ability to create data science projects useful in several different contexts:\n",
        "\n",
        "- Projects will help you build a portfolio, which is critical to finding a job as a data analyst or scientist.\n",
        "- Working on projects will help you learn new skills and reinforce existing concepts.\n",
        "- Most \"real-world\" data science and analysis work consists of developing internal projects.\n",
        "- Projects allow you to investigate interesting phenomena and satisfy your curiosity.\n",
        "\n",
        "Whether you aim to become a data scientist or analyst or you're just curious about the world, building projects can be immensely rewarding.\n",
        "\n",
        "[Here's](https://github.com/dataquestio/loan-prediction) an example of a finished project.\n",
        "\n",
        "In this mission, we'll walk through the first part of a complete data science project, including how to acquire the raw data. The project will focus on exploring and analyzing a data set. We'll develop our data cleaning and storytelling skills, which will enable us to build complete projects on our own.\n",
        "\n",
        "We'll focus primarily on data exploration in this mission. We'll also combine several messy data sets into a single clean one to make analysis easier. Over the next few missions, we'll work through the rest of our project and perform the actual analysis.\n",
        "\n",
        "The first step in creating a project is to decide on a topic. You want the topic to be something you're interested in and motivated to explore. It's very obvious when people are making projects just to make them, rather than out of a genuine interest in the topic.\n",
        "\n",
        "Here are two ways to go about finding a good topic:\n",
        "\n",
        "- Think about what sectors or angles you're really interested in, then find data sets relating to those sectors.\n",
        "- Review several data sets, and find one that seems interesting enough to explore.\n",
        "\n",
        "Whichever approach you take, you can start your search at these sites:\n",
        "\n",
        "- [Data.gov](https://www.data.gov/) - A directory of government data downloads\n",
        "- [/r/datasets](https://reddit.com/r/datasets) - A subreddit that has hundreds of interesting data sets\n",
        "- [Awesome datasets](https://github.com/caesar0301/awesome-public-datasets) - A list of data sets hosted on GitHub\n",
        "- [rs.io](http://rs.io/100-interesting-data-sets-for-statistics/) - A great blog post with hundreds of interesting data sets\n",
        "\n",
        "In real-world data science, you may not find an ideal data set. You might have to aggregate disparate data sources instead, or do a good amount of data cleaning.\n",
        "\n",
        "For the purposes of this project, we'll be using data about New York City public schools, which can be found [here](https://data.cityofnewyork.us/browse?category=Education)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TRI65HN9MK2"
      },
      "source": [
        "## 2. Finding All of the Relevant Data Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXYr1mRq9MNj"
      },
      "source": [
        "Once you've chosen a topic, you'll want to pick an angle to investigate. It's important to choose an angle that has enough depth to analyze, but isn't so complicated that it's difficult to get started. You want to finish the project, and you want your results to be interesting to others.\n",
        "\n",
        "One of the most controversial issues in the U.S. educational system is the efficacy of standardized tests, and whether they're unfair to certain groups. Given our prior knowledge of this topic, investigating the correlations between [SAT scores](https://en.wikipedia.org/wiki/SAT) and demographics might be an interesting angle to take. We could correlate SAT scores with factors like race, gender, income, and more.\n",
        "\n",
        "The SAT, or Scholastic Aptitude Test, is an exam that U.S. high school students take before applying to college. Colleges take the test scores into account when deciding who to admit, so it's fairly important to perform well on it.\n",
        "\n",
        "The test consists of three sections, each of which has 800 possible points. The combined score is out of 2,400 possible points (while this number has changed a few times, the data set for our project is based on 2,400 total points). Organizations often rank high schools by their average SAT scores. The scores are also considered a measure of overall school district quality.\n",
        "\n",
        "New York City makes its data [on high school SAT scores](https://data.cityofnewyork.us/Education/SAT-Results/f9bf-2cp4) available online, [as well as the demographics for each high school](https://data.cityofnewyork.us/Education/DOE-High-School-Directory-2014-2015/n3p6-zve2). The first few rows of the SAT data look like this:\n",
        "\n",
        "![img](https://s3.amazonaws.com/dq-content/sat.png)\n",
        "\n",
        "Unfortunately, combining both of the data sets won't give us all of the demographic information we want to use. We'll need to supplement our data with other sources to do our full analysis.\n",
        "\n",
        "The same website has several related data sets covering demographic information and test scores. Here are the links to all of the data sets we'll be using:\n",
        "\n",
        "- [SAT scores by school](https://data.cityofnewyork.us/Education/SAT-Results/f9bf-2cp4) - SAT scores for each high school in New York City\n",
        "- [School attendance](https://data.cityofnewyork.us/Education/School-Attendance-and-Enrollment-Statistics-by-Dis/7z8d-msnt) - Attendance information for each school in New York City\n",
        "- [Class size](https://data.cityofnewyork.us/Education/2010-2011-Class-Size-School-level-detail/urz7-pzb3) - Information on class size for each school\n",
        "- [AP test results](https://data.cityofnewyork.us/Education/AP-College-Board-2010-School-Level-Results/itfs-ms3e) - Advanced Placement (AP) exam results for each high school (passing an optional AP exam in a particular subject can earn a student college credit in that subject)\n",
        "- [Graduation outcomes](https://data.cityofnewyork.us/Education/Graduation-Outcomes-Classes-Of-2005-2010-School-Le/vh2h-md7a) - The percentage of students who graduated, and other outcome information\n",
        "- [Demographics](https://data.cityofnewyork.us/Education/School-Demographics-and-Accountability-Snapshot-20/ihfw-zy9j) - Demographic information for each school\n",
        "- [School survey](https://data.cityofnewyork.us/Education/NYC-School-Survey-2011/mnz3-dyi8) - Surveys of parents, teachers, and students at each school\n",
        "\n",
        "All of these data sets are interrelated. We'll need to combine them into a single data set before we can find correlations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7hOFmB9MRG"
      },
      "source": [
        "## 3. Finding Background Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1LMduv79MTJ"
      },
      "source": [
        "Before we move into coding, we'll need to do some background research. A thorough understanding of the data will help us avoid costly mistakes, such as thinking that a column represents something other than what it does. Background research will also give us a better understanding of how to combine and analyze the data.\n",
        "\n",
        "In this case, we'll want to research:\n",
        "\n",
        "- [New York City](https://en.wikipedia.org/wiki/New_York_City)\n",
        "- [The SAT](https://en.wikipedia.org/wiki/SAT)\n",
        "- [Schools in New York City](https://en.wikipedia.org/wiki/List_of_high_schools_in_New_York_City)\n",
        "- [Our data](https://data.cityofnewyork.us/browse?category=Education)\n",
        "\n",
        "We can learn a few different things from these resources. For example:\n",
        "\n",
        "- Only high school students take the SAT, so we'll want to focus on high schools.\n",
        "- New York City is made up of five boroughs, which are essentially distinct regions.\n",
        "- New York City schools fall within several different school districts, each of which can contains dozens of schools.\n",
        "- Our data sets include several different types of schools. We'll need to clean them so that we can focus on high schools only.\n",
        "- Each school in New York City has a unique code called a `DBN`, or district borough number.\n",
        "- Aggregating data by district will allow us to use the district mapping data to plot district-by-district differences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRBgMEiD9Qms"
      },
      "source": [
        "## 4. Reading in the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4NrrMRm9Qp0"
      },
      "source": [
        "Once we've done our background research, we're ready to read in the data. For your convenience, we've placed all the data into the `schools` folder. Here are all of the files in the folder:\n",
        "\n",
        "- `ap_2010.csv` - Data on [AP test results](https://data.cityofnewyork.us/Education/AP-College-Board-2010-School-Level-Results/itfs-ms3e)\n",
        "- `class_size.csv - Data on [class size](https://data.cityofnewyork.us/Education/2010-2011-Class-Size-School-level-detail/urz7-pzb3)\n",
        "- `demographics.csv` - Data on [demographics](https://data.cityofnewyork.us/Education/School-Demographics-and-Accountability-Snapshot-20/ihfw-zy9j)\n",
        "- `graduation.csv` - Data on [graduation outcomes](https://data.cityofnewyork.us/Education/Graduation-Outcomes-Classes-Of-2005-2010-School-Le/vh2h-md7a)\n",
        "- `hs_directory.csv` - A directory of [high schools](https://data.cityofnewyork.us/Education/DOE-High-School-Directory-2014-2015/n3p6-zve2)\n",
        "- `sat_results.csv` - Data on [SAT scores](https://data.cityofnewyork.us/Education/SAT-Results/f9bf-2cp4)\n",
        "- `survey_all.txt` - Data on [surveys](https://data.cityofnewyork.us/Education/NYC-School-Survey-2011/mnz3-dyi8) from all schools\n",
        "- `survey_d75.txt` - Data on [surveys](https://data.cityofnewyork.us/Education/NYC-School-Survey-2011/mnz3-dyi8) from New York City [district 75](http://schools.nyc.gov/academics/specialEducation/D75/default.htm)\n",
        "\n",
        "`survey_all.txt` and `survey_d75.txt` are in more complicated formats than the other files. For now, we'll focus on reading in the `CSV` files only, and then explore them.\n",
        "\n",
        "We'll read each file into a [pandas dataframe](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html), and then store all of the dataframes in a dictionary. This will give us a convenient way to store them, and a quick way to reference them later on.\n",
        "instructions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJxQpCK-FhhQ"
      },
      "source": [
        "**Instructions:**\n",
        "\n",
        "- Read each of the files in the list `data_files` into a pandas dataframe using the [pandas.read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function.\n",
        " - Recall that all of the data sets are in the `schools` folder. That means the path to `ap_2010.csv` is `schools/ap_2010.csv`.\n",
        "- Add each of the dataframes to the dictionary `data`, using the base of the filename as the key. For example, you'd enter `ap_2010` for the file `ap_2010.csv`.\n",
        "- Afterwards, `data` should have the following keys:\n",
        " - `ap_2010`\n",
        " - `class_size`\n",
        " - `demographics`\n",
        " - `graduation`\n",
        " - `hs_directory`\n",
        " - `sat_results`\n",
        "- In addition, each key in `data` should have the corresponding dataframe as its value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zbhVrbR2n44"
      },
      "source": [
        "# Read csv filea into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQVsg_sh2o4j"
      },
      "source": [
        "# Once you have completed verification, go to the CSV file in Google Drive, right-click on it and select “Get shareable link”, and cut out the unique id in the link.\n",
        "# \"ap_2010.csv\": https://drive.google.com/file/d/1KuI49etwQLsPS67JbVv4JPBcqPAh0bPe/view?usp=sharing\n",
        "id = \"1KuI49etwQLsPS67JbVv4JPBcqPAh0bPe\"\n",
        "\n",
        "# 'class_size.csv': https://drive.google.com/file/d/1KuI49etwQLsPS67JbVv4JPBcqPAh0bPe/view?usp=sharing\n",
        "id = \"1KuI49etwQLsPS67JbVv4JPBcqPAh0bPe\"\n",
        "\n",
        "# 'demographics.csv': https://drive.google.com/file/d/1gsKvOdzOBl2gllcOycsTRIv6n5q_uyjU/view?usp=sharing\n",
        "id = \"1gsKvOdzOBl2gllcOycsTRIv6n5q_uyjU\"\n",
        "\n",
        "# 'graduation.csv': https://drive.google.com/file/d/1EA4qZSFxAtnkiA0XeZuhFuIUoRnd844H/view?usp=sharing\n",
        "id = \"1EA4qZSFxAtnkiA0XeZuhFuIUoRnd844H\"\n",
        "\n",
        "# 'hs_directory.csv': https://drive.google.com/file/d/1JkSe5aOrSbBonyeY_1cbv2HQi_K27YnR/view?usp=sharing\n",
        "id = \"1JkSe5aOrSbBonyeY_1cbv2HQi_K27YnR\"\n",
        "\n",
        "# 'sat_results.csv': https://drive.google.com/file/d/1ccb_BgcwfoBveOQQ7iqvRPuDvqP3BQFt/view?usp=sharing\n",
        "id = \"1ccb_BgcwfoBveOQQ7iqvRPuDvqP3BQFt\"\n",
        "\n",
        "# 'survey_all.txt': https://drive.google.com/file/d/1f1czoKEPHDtyM7u6Kr6FJbNOPZfy4rD6/view?usp=sharing\n",
        "id = \"1f1czoKEPHDtyM7u6Kr6FJbNOPZfy4rD6\"\n",
        "\n",
        "# 'survey_d75.txt': https://drive.google.com/file/d/1HZMJ3JYHDFZcv6sDSMqP2_CElIU_e5UX/view?usp=sharing\n",
        "id = \"1HZMJ3JYHDFZcv6sDSMqP2_CElIU_e5UX\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgFvCD-32wdh"
      },
      "source": [
        "# Download the dataset\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('ap_2010.csv')\n",
        "downloaded.GetContentFile('class_size.csv')\n",
        "downloaded.GetContentFile('demographics.csv')\n",
        "downloaded.GetContentFile('graduation.csv')\n",
        "downloaded.GetContentFile('hs_directory.csv')\n",
        "downloaded.GetContentFile('sat_results.csv')\n",
        "downloaded.GetContentFile('survey_all.txt')\n",
        "downloaded.GetContentFile('survey_d75.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClvtIatlGQgA"
      },
      "source": [
        "# Provided code:\n",
        "\n",
        "import pandas as pd\n",
        "data_files = [\n",
        "    \"ap_2010.csv\",\n",
        "    \"class_size.csv\",\n",
        "    \"demographics.csv\",\n",
        "    \"graduation.csv\",\n",
        "    \"hs_directory.csv\",\n",
        "    \"sat_results.csv\"\n",
        "]\n",
        "data = {}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDeJ9ArIGURd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "0fe95708-c608-4800-9b54-331936573829"
      },
      "source": [
        "# Solution\n",
        "\n",
        "for f in data_files:\n",
        "    d = pd.read_csv(\"schools/{0}\".format(f))\n",
        "    key_name = f.replace(\".csv\", \"\")\n",
        "    data[key_name] = d"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7d5e6d1ebec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"schools/{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mkey_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'schools/ap_2010.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRPCiT-j9Qs-"
      },
      "source": [
        "## 5. Exploring the SAT Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZotKtiS9QvD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAkqR9oI9Q1u"
      },
      "source": [
        "## 6. Exploring the Remaining Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50CQ_Vjb9Q4O"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oIPRMVK9Q7W"
      },
      "source": [
        "## 7. Reading in the Survey Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy8TTFfM9Q-B"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqZEIU6H9RA_"
      },
      "source": [
        "## 8. Reading in the Survey Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jbK9H8M9RDY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT2oMs0e9RRO"
      },
      "source": [
        "## 9. Cleaning Up the Surveys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Vl7fLG9RUF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad8o8wZ79RW3"
      },
      "source": [
        "## 10. Inserting DBN Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0vnyTMZ-n8P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRsfeuFz-n_w"
      },
      "source": [
        "## 11. Inserting DBN Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IazrEdjt-oDR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lVmhfsm-oGe"
      },
      "source": [
        "## 12. Combining the SAT Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4q54h33-oKK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpQVe5G1-oMr"
      },
      "source": [
        "## 13. Parsing Geographic Coordinates for Schools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYPcJJ1k-tWi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8ycQISY-tbU"
      },
      "source": [
        "## 14. Extracting the Longitude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl3Rbrdi-vUL"
      },
      "source": [
        ""
      ]
    }
  ]
}